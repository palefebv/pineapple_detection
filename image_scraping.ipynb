{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR MAGES WITHOUT A PERSON\n",
    "def scrape_images(search_terms, site_searches=[]):\n",
    "    print(\"SEARCHING FOR: \"+str(search_terms))\n",
    "    photo_list = []\n",
    "    \n",
    "    for search_term in search_terms:\n",
    "        if 'adobe' in site_searches or 'all' in site_searches:\n",
    "            try:\n",
    "                page = requests.get(\"https://stock.adobe.com/search?filters%5Bcontent_type%3Aphoto%5D=1&filters%5Bcontent_type%3Aillustration%5D=1&filters%5Bcontent_type%3Azip_vector%5D=1&filters%5Bcontent_type%3Avideo%5D=1&filters%5Bcontent_type%3Atemplate%5D=1&filters%5Bcontent_type%3A3d%5D=1&filters%5Bcontent_type%3Aimage%5D=1&filters%5Borientation%5D=square&filters%5Breleases%3Ais_exclude%5D=1&filters%5Bisolated%5D=only&k=\"+search_term+\"&order=relevance&safe_search=1&search_type=filter-select&limit=100&search_page=1&get_facets=1\").text\n",
    "                soup = BeautifulSoup(page, 'lxml')\n",
    "                photos = soup.find(\"div\", {\"id\": \"search-results\"}).find_all(\"div\",{\"class\": \"search-result-cell\"})\n",
    "                for photo in photos:\n",
    "                    if not \"spacer\" in photo.find(\"div\", {\"class\": \"thumb-frame\"}).find(\"a\").find(\"img\")[\"src\"]:\n",
    "                        photo_list.append(photo.find(\"div\", {\"class\": \"thumb-frame\"}).find(\"a\").find(\"img\")[\"src\"])        \n",
    "            except Exception as e:\n",
    "                print(\"ADOBE: \"+str(e))\n",
    "\n",
    "        if 'istock' in site_searches or 'all' in site_searches:\n",
    "            try:\n",
    "                page = requests.get(\"https://www.istockphoto.com/photos/\"+search_term+\"?numberofpeople=none&orientations=square&phrase=\"+search_term+\"&sort=mostpopular\").text\n",
    "                soup = BeautifulSoup(page, 'lxml')\n",
    "                photos = soup.find(\"div\", {\"class\": \"search-content__gallery-assets\"}).find_all(\"gi-asset\")\n",
    "                for photo in photos:\n",
    "                    photo_list.append(photo.find(\"article\").find(\"a\").find(\"figure\").find(\"img\")[\"src\"])        \n",
    "            except Exception as e:\n",
    "                print(\"ISTOCK: \"+str(e))\n",
    "        if 'getty' in site_searches or 'all' in site_searches:        \n",
    "            try:\n",
    "                page = requests.get(\"https://www.gettyimages.com/photos/\"+search_term+\"?license=rf&compositions=portrait,closeup,stilllife&family=creative&numberofpeople=none&orientations=square&phrase=\"+search_term+\"&sort=mostpopular#license\").text\n",
    "                soup = BeautifulSoup(page, 'lxml')\n",
    "                photos = soup.find(\"div\", {\"class\": \"search-content__gallery-assets\"}).find_all(\"gi-asset\", {\"class\": \"gallery-mosaic-asset\"})\n",
    "                for photo in photos:\n",
    "                    photo_list.append(photo.find(\"article\").find(\"a\").find(\"figure\").find(\"img\")[\"src\"])\n",
    "            except Exception as e:\n",
    "                print(\"GETTY: \"+str(e))\n",
    "\n",
    "        if 'flickr' in site_searches or 'all' in site_searches:\n",
    "            try:\n",
    "                page = requests.get(\"https://www.flickr.com/search/?media=photos&text=\"+search_term+\"&orientation=square\").text\n",
    "                soup = BeautifulSoup(page, 'lxml')\n",
    "                photos_container = soup.find(\"div\", {\"class\": \"photo-list-view\"})\n",
    "                if photos_container:\n",
    "                    photos = photos_container.find_all(\"div\", {\"class\": \"photo-list-photo-view\"})\n",
    "                    for photo in photos:\n",
    "                        style = photo['style']\n",
    "                        style_list = list(style.split(\";\")) \n",
    "                        photo_list.append(\"http:\" + style_list[5].split(\":\")[1].split(\"(\")[1].split(\")\")[0])\n",
    "            except Exception as e:\n",
    "                print(\"FLICKR: \"+str(e))\n",
    "                \n",
    "        if 'google' in site_searches or 'all' in site_searches:\n",
    "            try:\n",
    "                page = requests.get(\"https://www.google.com/search?tbm=isch&q=\"+search_term+\"&sa=X&biw=1400&bih=620&dpr=2\").text\n",
    "                soup = BeautifulSoup(page, 'lxml')\n",
    "                photos = soup.find_all(\"img\", {\"class\":\"t0fcAb\"})\n",
    "                for photo in photos:\n",
    "                    photo_list.append(photo['src'])\n",
    "            except Exception as e:\n",
    "                print(\"GOOGLE: \"+str(e))\n",
    "        \n",
    "\n",
    "    return photo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR IMAGES OF A PERSON\n",
    "# def scrape_images_person(search_terms, site_searches=[]):\n",
    "#     photo_list = []\n",
    "    \n",
    "#     for search_term in search_terms:\n",
    "#         if 'adobe' in site_searches or 'all' in site_searches:            \n",
    "#             try:\n",
    "#                 for x in range(1,101):            \n",
    "#                     page = requests.get(\"https://stock.adobe.com/search?filters%5Bcontent_type%3Aphoto%5D=1&filters%5Bcontent_type%3Aillustration%5D=1&filters%5Bcontent_type%3Azip_vector%5D=1&filters%5Bcontent_type%3Avideo%5D=1&filters%5Bcontent_type%3Atemplate%5D=1&filters%5Bcontent_type%3A3d%5D=1&filters%5Bcontent_type%3Aimage%5D=1&filters%5Breleases%3Ais_include%5D=1&filters%5Borientation%5D=square&filters%5Bisolated%5D=only&k=\"+search_term+\"&order=relevance&safe_search=1&search_type=filter-select&limit=100&search_page=\"+str(x)+\"&get_facets=1\").text\n",
    "#                     soup = BeautifulSoup(page, 'lxml')\n",
    "#                     photos = soup.find(\"div\", {\"id\": \"search-results\"}).find_all(\"div\",{\"class\": \"search-result-cell\"})\n",
    "#                     for photo in photos:\n",
    "#                         if not \"spacer\" in photo.find(\"div\", {\"class\": \"thumb-frame\"}).find(\"a\").find(\"img\")[\"src\"]:\n",
    "#                             photo_list.append(photo.find(\"div\", {\"class\": \"thumb-frame\"}).find(\"a\").find(\"img\")[\"src\"])        \n",
    "#             except Exception as e:\n",
    "#                 print(\"ADOBE: \"+str(e))\n",
    "        \n",
    "#         if \"istock\" in site_searches or 'all' in site_searches:\n",
    "#             try:\n",
    "#                 for x in range(1,101):            \n",
    "#                     page = requests.get(\"https://www.istockphoto.com/photos/\"+search_term+\"?numberofpeople=one&page=\"+str(x)+\"&orientations=square&phrase=\"+search_term+\"&sort=mostpopular\").text\n",
    "#                     soup = BeautifulSoup(page, 'lxml')\n",
    "#                     photos = soup.find(\"div\", {\"class\": \"search-content__gallery-assets\"}).find_all(\"gi-asset\")\n",
    "#                     for photo in photos:\n",
    "#                         photo_list.append(photo.find(\"article\").find(\"a\").find(\"figure\").find(\"img\")[\"src\"])        \n",
    "#             except Exception as e:\n",
    "#                 print(\"ISTOCK: \"+str(e))\n",
    "                \n",
    "#         if \"getty\" in site_searches or 'all' in site_searches:        \n",
    "#             try:\n",
    "#                 for x in range(1,101):\n",
    "#                     page = requests.get(\"https://www.gettyimages.com/photos/\"+search_term+\"?license=rf&compositions=portrait,closeup,stilllife&family=creative&page=\"+str(x)+\"&numberofpeople=1&orientations=square&phrase=\"+search_term+\"&sort=mostpopular#license\").text\n",
    "#                     soup = BeautifulSoup(page, 'lxml')\n",
    "#                     photos = soup.find(\"div\", {\"class\": \"search-content__gallery-assets\"}).find_all(\"gi-asset\", {\"class\": \"gallery-mosaic-asset\"})\n",
    "#                     for photo in photos:\n",
    "#                         photo_list.append(photo.find(\"article\").find(\"a\").find(\"figure\").find(\"img\")[\"src\"])\n",
    "#             except Exception as e:\n",
    "#                 print(\"GETTY: \"+str(e))\n",
    "                \n",
    "#         if \"flickr\" in site_searches or 'all' in site_searches:\n",
    "#             try:\n",
    "#                 page = requests.get(\"https://www.flickr.com/search/?media=photos&text=\"+search_term+\"&orientation=square\").text\n",
    "#                 soup = BeautifulSoup(page, 'lxml')\n",
    "#                 photos_container = soup.find(\"div\", {\"class\": \"photo-list-view\"})\n",
    "#                 if photos_container:\n",
    "#                     photos = photos_container.find_all(\"div\", {\"class\": \"photo-list-photo-view\"})\n",
    "#                     for photo in photos:\n",
    "#                         style = photo['style']\n",
    "#                         style_list = list(style.split(\";\")) \n",
    "#                         photo_list.append(\"http:\" + style_list[5].split(\":\")[1].split(\"(\")[1].split(\")\")[0])\n",
    "#             except Exception as e:\n",
    "#                 print(\"FLICKR: \"+str(e))\n",
    "        \n",
    "#         if \"google\" in site_searches or 'all' in site_searches:        \n",
    "#             try:\n",
    "#                 page = requests.get(\"https://www.google.com/search?tbm=isch&q=\"+search_term+\"&sa=X&biw=1400&bih=620&dpr=2\").text\n",
    "#                 soup = BeautifulSoup(page, 'lxml')\n",
    "#                 photo_rows = soup.find_all(\"td\")\n",
    "#                 for photo_row in photo_rows:\n",
    "#                     image_url = photo_row.find('a').find('img')['src']\n",
    "#                     photo_list.append(image_url)\n",
    "#             except Exception as e:\n",
    "#                 print(\"GOOGLE: \"+str(e))\n",
    "#     print(len(photo_list))\n",
    "\n",
    "#     return photo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\"pineapple\",\"pineapple+fruit\",\"pineappe+plant\", \"pineapple+plantation\", \"pineapple+field\", \"pineapple+fruit+stand\", \"pineapple+fruit+store\"]\n",
    "\n",
    "# search_terms = [\"asian+male+profile\",\"african+american+male+profile\",\"white+male+profile\",\"european+male+profile\",\"indian+male+profile\",\n",
    "#                    \"latino+male+profile\",\"english+male+profile\",\"black+male+profile\",\"french+male+profile\",\"young+male+profile\",\"older+male+profile\"]\n",
    "\n",
    "# search_terms = [\"african+american+woman+studio+shot\",\"african+american+woman+close+up\",\"african+american+female+studio+shot\",\"african+american+female+face\",\"african+american+woman+face\",\n",
    "#                   \"african+american+woman+portait\",\"african+american+woman+head+and+shoulders\",\"african+american+woman+face+isolated\",\n",
    "#                   \"african+american+woman+smiling+close+up\"+\"african+american+female+frowning+close+up\",\"close-up+of+african+american+woman\",\"close-up+of+african+american+female\",\n",
    "#                   \"african+american+woman+laughing+close+up\",\"african+american+woman+angry+close+up\",\"african+american+woman+single+close+up\",\n",
    "#                   \"african+american+woman+open+mouth+close+up\",\"african+american+woman+with+glasses+close+up\",\"african+american+woman+head+shoulders+close+up\",\"african+american+woman+drinking+close+up\",\n",
    "#                   \"african+american+woman+crying+close+up\",\"african+american+woman+surprised+close+up\",\"african+american+woman+calm+close+up\",\"african+american+female+concerned+close+up\",\n",
    "#                   \"african+american+female+talking+close+up\",\"african+american+woman+shouting+close+up\",\"african+american+female+young+close+up\",\"african+american+female+elderly+close+up\",\n",
    "#                   \"african+american+female+black+close+up\",\"african+american+female+white+close+up\",\"african+american+female+close+up\",\"african+american+female+close+up\",\n",
    "#                   \"african+american+female+european+close+up\",\"african+american+female+african+american+close+up\",\"african+american+female+middle+age+close+up\",\n",
    "#                   \"african+american+female+thin+studio+shot\",\"african+american+female+heavy+studio+shot\",\"african+american+female+bald+close+up\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCHING FOR: ['pineapple', 'pineapple+fruit', 'pineappe+plant', 'pineapple+plantation', 'pineapple+field', 'pineapple+fruit+stand', 'pineapple+fruit+store']\n"
     ]
    }
   ],
   "source": [
    "image_list = scrape_images(search_terms, [\"all\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n"
     ]
    }
   ],
   "source": [
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_raw_images(image_url_list, directory):\n",
    "    pic_num = 1    \n",
    "    for image_url in image_url_list:\n",
    "        try:\n",
    "            urllib.request.urlretrieve(image_url, directory+\"pineapple\"+str(pic_num)+\".jpg\")\n",
    "            pic_num += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_raw_images(image_list, \"dataset/images/\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_raw_images(directory):\n",
    "    pic_num = 1\n",
    "    for base_img in os.listdir(directory):\n",
    "        pic_num += 1\n",
    "        try:\n",
    "            img = cv2.imread(directory+\"/\"+base_img)\n",
    "            angle = int(random.uniform(-30, 30))\n",
    "            h, w = img.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "            img = cv2.warpAffine(img, M, (w, h))\n",
    "            cv2.imwrite(directory+'/pineapple_aug'+str(pic_num)+\".jpg\", img)\n",
    "        except Exception as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "augment_raw_images(\"dataset/images/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
